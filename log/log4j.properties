# Réduire les logs de Spark
log4j.logger.org.apache.spark=ERROR
log4j.logger.org.apache.kafka=ERROR
log4j.logger.org.apache.spark.sql.execution=ERROR
log4j.logger.org.apache.spark.streaming=ERROR

# Réduire encore plus les logs des sources Kafka
log4j.logger.kafka=ERROR
log4j.logger.org.apache.spark.sql.kafka010=ERROR

# Logs de traitement (par exemple, pour les jobs Spark Streaming)
log4j.logger.org.apache.spark.streaming.kafka010=ERROR
log4j.logger.org.apache.spark.sql.streaming=ERROR

# Réduire les logs des écritures dans le Data Lake et des checkpoints
log4j.logger.org.apache.spark.sql.execution.datasources=ERROR
log4j.logger.org.apache.spark.sql.execution.streaming=ERROR

# Root Logger (niveau minimal pour tout sauf erreurs)
log4j.rootLogger=ERROR, console

# Configuration pour le logging sur la console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{ISO8601} %5p [%t] (%F:%L) - %m%n
